{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "#those are optional and are not necessary for training\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# We now prepare the training and test data. The dataset includes patients' information along \n",
    "# with a 10-year risk of future coronary heart disease (CHD) as a label. The goal is to build\n",
    "# a model that can predict this 10-year CHD risk based on patients' information.\n",
    "# random_data() function that generates random, linearly separable points,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([780, 9])\n",
      "y_train has shape: torch.Size([780, 1])\n",
      "x_test has shape: torch.Size([334, 9])\n",
      "y_test has shape: torch.Size([334, 1])\n",
      "#######################################\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)\n",
    "\n",
    "\n",
    "def split_train_test(x, y, test_ratio=0.3):\n",
    "    idxs = [i for i in range(len(x))]\n",
    "    random.shuffle(idxs)\n",
    "    # delimiter between test and train data\n",
    "    delim = int(len(x) * test_ratio)\n",
    "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
    "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
    "\n",
    "\n",
    "def heart_disease_data():\n",
    "    data = pd.read_csv(\"./data/framingham.csv\")\n",
    "    # drop rows with missing values\n",
    "    data = data.dropna()\n",
    "    # drop some features\n",
    "    data = data.drop(columns=[\"education\", \"currentSmoker\", \"BPMeds\", \"diabetes\", \"diaBP\", \"BMI\"])\n",
    "    # balance data\n",
    "    grouped = data.groupby('TenYearCHD')\n",
    "    data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "    # extract labels\n",
    "    y = torch.tensor(data[\"TenYearCHD\"].values).float().unsqueeze(1)\n",
    "    data = data.drop(\"TenYearCHD\", 'columns')\n",
    "    # standardize data\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    x = torch.tensor(data.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "\n",
    "def random_data(m=1024, n=2):\n",
    "    # data separable by the line `y = x`\n",
    "    x_train = torch.randn(m, n)\n",
    "    x_test = torch.randn(m // 2, n)\n",
    "    y_train = (x_train[:, 0] >= x_train[:, 1]).float().unsqueeze(0).t()\n",
    "    y_test = (x_test[:, 0] >= x_test[:, 1]).float().unsqueeze(0).t()\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "# You can use whatever data you want without modification to the tutorial\n",
    "# x_train, y_train, x_test, y_test = random_data()\n",
    "x_train, y_train, x_test, y_test = heart_disease_data()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Logistic Regression Model\n",
    "# start training a logistic regression model (without any encryption) which can be viewed as \n",
    "# a single layer neural network with a single node.\n",
    "# Will use this model as a means of comparison against encrypted training and evaluation\n",
    "\n",
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = LR(n_features)\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 0.8504331111907959\n",
      "Loss at epoch 2: 0.6863380670547485\n",
      "Loss at epoch 3: 0.6358120441436768\n",
      "Loss at epoch 4: 0.6193529367446899\n",
      "Loss at epoch 5: 0.6124345064163208\n"
     ]
    }
   ],
   "source": [
    "#define the number of epochs for both plain and encrypted training\n",
    "EPOCHS = 5\n",
    "\n",
    "def train(model,  optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f\"Loss at epoch {e}: {loss.data}\")\n",
    "    return model\n",
    "\n",
    "model = train(model, optim, criterion, x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy on plain test_set: 0.703592836856842\n"
     ]
    }
   ],
   "source": [
    "def accuracy(mode, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "plain_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Accuarcy on plain test_set: {plain_accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encrypted Evaluation \n",
    "# Evaluating the logistic regression model with plain parameters (optionally encrypted parameters)\n",
    "# on the encrypted test set. We first create a PyTorch-like LR model that can evaluate encrypted data:\n",
    "\n",
    "class EncryptedLR:\n",
    "    def __init__(self, torch_lr):\n",
    "        #TenSEAL processes lists and not torch tensors,\n",
    "        # so we take out the parameters from the PyTorch model\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        #We dont need to perform sigmoid as this model\n",
    "        # will only be used for evaluation, and the label \n",
    "        # can be deduced without applying sigmoid\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        return enc_out\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    ### we can use the functions below to perform \n",
    "    ## the evaluation with an encrypted model\n",
    "    \n",
    "    def encrypt(self,  context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self, context):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "eelr = EncryptedLR(model)\n",
    "\n",
    " # We now create a TenSEAL Context for specifying the scheme and the parameters we are going\n",
    "    # to use. Here we choose small and secure parameters that allow us to make a single\n",
    "    # multiplication. That's enough for evaluating a logistic regression model, however we will\n",
    "    # see that we need larger parameters when doing training on encrypted data.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 4096\n",
    "coeff_mod_bit_sizes = [40, 20, 40]\n",
    "# create TenSEALContext\n",
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test-set took 0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Encrypt the whole set before the evaluation\n",
    "t_start = time()\n",
    "enc_x_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in x_test]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the test-set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated test set of 334 entries in 0 seconds\n",
      "Accuracy: 217/334 = 0.6497005988023952\n",
      "Difference between plain and encrypted accuracies: 0.05389225482940674\n"
     ]
    }
   ],
   "source": [
    "# (optional) encrypt the model's parameters\n",
    "# eelr.encrypt(ctx_eval)\n",
    "\n",
    "\n",
    "# built the EncryptedLR (Logistic Regression) class,dont compute the sigmoid function on the\n",
    "# encrypted output of the linear layer, simply because its not needed, and computing sigmoid \n",
    "# over encrypted data will increase the computation time and require larger encryption\n",
    "# parameters. However we will use sigmoid for the encrypted  training part. We now proceed \n",
    "# with the evaluation of the encrypted test set and compare the accuracy to the one on the \n",
    "# plain test set.\n",
    "\n",
    "def encrypted_evaluation(model, enc_x_test, y_test):\n",
    "    t_start = time()\n",
    "    \n",
    "    correct = 0\n",
    "    for enc_x, y in zip(enc_x_test, y_test):\n",
    "        #encrypted evaluation\n",
    "        enc_out = model(enc_x)\n",
    "        #plain comparison\n",
    "        out = enc_out.decrypt()\n",
    "        out = torch.tensor(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        if torch.abs(out - y) < 0.5:\n",
    "            correct += 1\n",
    "    t_end = time()\n",
    "    print(f\"Evaluated test set of {len(x_test)} entries in {int(t_end - t_start)} seconds\")\n",
    "    print(f\"Accuracy: {correct}/{len(x_test)} = {correct / len(x_test)}\")\n",
    "    return correct / len(x_test)\n",
    "\n",
    "encrypted_accuracy = encrypted_evaluation(eelr, enc_x_test, y_test)\n",
    "diff_accuracy = plain_accuracy - encrypted_accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
    "if diff_accuracy < 0:\n",
    "    print(\"Oh! We got a better accuracy on the encrypted test-set! The noise was on our side...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training an Encrypted Logistic Regression Model on Encrypted Data\n",
    "# In this part, we will redefine a PyTorch-like model that can both forward encrypted data\n",
    "# as well as backpropagate to update the weights and thus train the encrypted logistic \n",
    "# regression model on encrypted data.\n",
    "# Loss Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        # we accumulate gradients and counts the number of iterations\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
    "        return enc_out\n",
    "    \n",
    "    def backward(self, enc_x, enc_out, enc_y):\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        self._delta_w += enc_x * out_minus_y\n",
    "        self._delta_b += out_minus_y\n",
    "        self._count += 1\n",
    "        \n",
    "    def update_parameters(self):\n",
    "        if self._count == 0:\n",
    "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
    "        # update weights\n",
    "        # We use a small regularization term to keep the output\n",
    "        # of the linear layer in the range of the sigmoid approximation\n",
    "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
    "        self.bias -= self._delta_b * (1 / self._count)\n",
    "        # reset gradient accumulators and iterations count\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        # We use the polynomial approximation of degree 3\n",
    "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
    "        # from https://eprint.iacr.org/2018/462.pdf\n",
    "        # which fits the function pretty well in the range [-5,5]\n",
    "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "    \n",
    "    def plain_accuracy(self, x_test, y_test):\n",
    "        # evaluate accuracy of the model on\n",
    "        # the plain (x_test, y_test) dataset\n",
    "        w = torch.tensor(self.weight)\n",
    "        b = torch.tensor(self.bias)\n",
    "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()    \n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40,21,21,21,21,21,21,40]\n",
    "# create TenSEALContext \n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the training_set took 9 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
    "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution on plain data: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution on encrypted data:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Since our sigmoid approximation is only good in the range [-5,5], we want to have\n",
    "# all its inputs in that range. In order to do this, we need to keep our logistic regression\n",
    "# parameters as well as possible, so we apply regularization.\n",
    "\n",
    "# Note: Keeping the parameters small certainly reduces the magnitude of the output, but we can\n",
    "# also get out of range if the data wasn't standardized. We may have spotted that we \n",
    "# standardized the data with a mean of 0 and std of 1, this was both for better performance,\n",
    "# as well as to keep the inputs to the sigmoid in the desired range.\n",
    "\n",
    "normal_dist = lambda x, mean, var: np.exp(- np.square(x - mean) / (2 * var)) / np.sqrt(2 * np.pi * var)\n",
    "\n",
    "def plot_normal_dist(mean, var, rmin= -10, rmax=10):\n",
    "    x = np.arange(rmin, rmax, 0.01)\n",
    "    y = normal_dist(x, mean, var)\n",
    "    fig = plt.plot(x, y)\n",
    "\n",
    "# plain distribution\n",
    "lr = LR(n_features)\n",
    "data = lr.lr(x_test)\n",
    "mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "plot_normal_dist(mean, var)\n",
    "print(\"Distribution on plain data: \")\n",
    "plt.show()\n",
    "\n",
    "#encrypted distribution\n",
    "def encrypted_out_distribution(eelr, enc_x_test):\n",
    "    w = eelr.weight\n",
    "    b = eelr.bias\n",
    "    data = []\n",
    "    for enc_x in enc_x_test:\n",
    "        enc_out = enc_x.dot(w) + b\n",
    "        data.append(enc_out.decrypt())\n",
    "    data = torch.tensor(data)\n",
    "    mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "    plot_normal_dist(mean, var)\n",
    "    print(\"Distribution on encrypted data:\")\n",
    "    plt.show()\n",
    "\n",
    "eelr = EncryptedLR(lr)\n",
    "eelr.encrypt(ctx_training)\n",
    "encrypted_out_distribution(eelr, enc_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at epoch #0 is 0.443113774061203\n",
      "Accuracy at epoch #1 is 0.6706587076187134\n",
      "Accuracy at epoch #2 is 0.6646706461906433\n",
      "Accuracy at epoch #3 is 0.6796407103538513\n",
      "Accuracy at epoch #4 is 0.6856287717819214\n",
      "Accuracy at epoch #5 is 0.6766467094421387\n",
      "\n",
      "Average time per epoch: 48 seconds\n",
      "Final accuracy is 0.6766467094421387\n",
      "Difference between plain and encrypted accuracies: 0.02694612741470337\n"
     ]
    }
   ],
   "source": [
    "# Training an encrypted logistic regression model on encrypted data! We decrypt the weights \n",
    "# and reencrypt them again after every epoch, this is necessary since after updating the \n",
    "# the weights at at the end of the epoch, we can no longer use them perform enough \n",
    "# multiplications, so we need to get them back to the initial ciphertext level. \n",
    "# In a real scenario, this would translate to sending the weight back to the secret-key\n",
    "# holder for decryption and re-encryption. In that case, it will result in just a few Kilobytes\n",
    "# communication per epoch.\n",
    "\n",
    "eelr = EncryptedLR(LR(n_features))\n",
    "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
    "\n",
    "times = []\n",
    "for epoch in range(EPOCHS):\n",
    "    eelr.encrypt(ctx_training)\n",
    "    \n",
    "    # if you want to keep an eye on the distribution to make sure\n",
    "    # the function approxiamation is still working fine\n",
    "    # WARNING: this operation is time consuming\n",
    "    # encrypted_out_distribution(eelr, enc_x_train)\n",
    "    \n",
    "    t_start = time()\n",
    "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
    "        enc_out = eelr.forward(enc_x)\n",
    "        eelr.backward(enc_x, enc_out, enc_y)\n",
    "    eelr.update_parameters()\n",
    "    t_end = time()\n",
    "    times.append(t_end - t_start)\n",
    "    \n",
    "    eelr.decrypt()\n",
    "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
    "\n",
    "\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "print(f\"Final accuracy is {accuracy}\")\n",
    "\n",
    "diff_accuracy = plain_accuracy - accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
    "if diff_accuracy < 0:\n",
    "    print(\"Oh! We got a better accuracy when training on encrypted data! The noise was on our side...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
